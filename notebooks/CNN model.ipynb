{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio classification using convolutional neural networks\n",
    "\n",
    "\n",
    "Audio classification can be performed by converting audio streams into [spectrograms](https://en.wikipedia.org/wiki/Spectrogram), which provide visual representations of spectrums of frequencies as they vary over time, and classifying the spectrograms using [convolutional neural networks](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNNs). The spectrograms below were generated from WAV files with vocal sounds, such as coughing, laughing, tapping etc.. We shall use Tensorflow Keras to build a CNN that can identify the various vocal sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir_train = \"../data/original_audio/train\"\n",
    "base_dir_test  = \"../data/original_audio/test\"\n",
    "train_input_dirs  = [os.path.join(base_dir_train, dir)       \n",
    "                     for dir in os.listdir(base_dir_train) if \"DS_Store\" not in dir] \n",
    "test_input_dirs   = [os.path.join(base_dir_test, dir) \n",
    "                     for dir in os.listdir(base_dir_test) if \"DS_Store\" not in dir] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Audio Data\n",
    "\n",
    "### Importing Required Libraries and Setting Parameters\n",
    "\n",
    "Firstly, we set up the Mel and the MFCC (Mel-frequency cepstral coefficients) parameters, define the number of categories, and create a mapping for our categories.\n",
    "\n",
    "### Preprocessing and Preparing the Data\n",
    "\n",
    "Next, we preprocess our training and test data: The `preprocess` function (imported from `src.preprocess`) is used to extract features from our audio files. We then convert the features and labels into numpy arrays, mapping the categorical labels to their corresponding numeric values.\n",
    "\n",
    "### Normalizing the Data and Encoding Labels\n",
    "\n",
    "Finally, we normalize our feature data and encode our labels: We normalize the feature data to a range between 0 and 1 using min-max normalization. This helps in faster convergence during model training. The labels are then one-hot encoded using `to_categorical` from Keras. This converts our numeric labels into binary class matrices, which is the format required for multi-class classification problems.\n",
    "\n",
    "After these preprocessing steps, our data is ready to be fed into the CNN model for training and evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from src.preprocess import preprocess\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len = 2\n",
    "verbose   = 0\n",
    "sr        = 16000\n",
    "mels_params  = {\"hop_length\":128, \"n_fft\":2048, \"n_mels\":224}\n",
    "mfcc_params  = {\"hop_length\":256, \"n_fft\":2048, \"n_mfcc\":128}\n",
    "params       = mfcc_params\n",
    "n_categories = 2\n",
    "\n",
    "if n_categories == 4:\n",
    "    categories = [\"tapping\", \"talking\", \"laughing\", \"cough\"]\n",
    "    map_cat    = { \"tapping\":0, \"talking\":1, \"laughing\":2, \"cough\":3}\n",
    "elif n_categories == 2:\n",
    "    map_cat    = {\"laughing\":0, \"talking\":0, \"tapping\":0, \"cough\":1}\n",
    "    categories = [\"other\", \"cough\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_features, train_labels) = preprocess(train_input_dirs, params)\n",
    "(test_features,  test_labels)  = preprocess(test_input_dirs , params)\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array([map_cat[label] for label in train_labels])\n",
    "\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array([map_cat[label] for label in test_labels])\n",
    "\n",
    "X_train_norm = (X_train - X_train.min()) / (X_train.max() - X_train.min())\n",
    "X_test_norm  = (X_test  - X_train.min()) / (X_train.max() - X_train.min())\n",
    "\n",
    "y_train_encoded = to_categorical(y_train)\n",
    "y_test_encoded = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and train a CNN\n",
    "\n",
    "State-of-the-art image classification is typically performed with convolutional neural networks that use [convolution layers](https://machinelearningmastery.com/convolutional-layers-for-deep-learning-neural-networks/) to extract features from images and [pooling layers](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/) to downsize images so that features can be detected at various resolutions. The next task is to build a CNN containing a series of convolution and pooling layers for feature extraction, a pair of fully connected layers for classification, and a `softmax` layer that outputs probabilities for each class, and to train it with spectrogram images and labels. Start by defining the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"softmax\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "\n",
    "activation = \"sigmoid\"\n",
    "loss = \"binary_crossentropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model import create_model\n",
    "from tensorflow.keras.optimizers.legacy import Adam \n",
    "model = create_model(X_train_norm.shape[1:], n_categories, activation=activation)\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(X_train_norm, y_train_encoded, \n",
    "                 validation_data=(X_test_norm, y_test_encoded), \n",
    "                 batch_size=16, \n",
    "                 epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model in SavedModel format\n",
    "model.save(\"../model/mfcc_cnn_model\")\n",
    "\n",
    "# Optionally, you can also save the model weights separately\n",
    "model.save_weights(\"../model/mfcc_cnn_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the model architecture\n",
    "loaded_model = create_model(X_train_norm.shape[1:], n_categories, activation=\"softmax\")\n",
    "\n",
    "# Compile the model (use the same configuration as when you trained it)\n",
    "loaded_model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Load the weights\n",
    "loaded_model.load_weights(\"../model/mfcc_cnn_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the training and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_utils import plot_train_val_metrics\n",
    "plot_train_val_metrics(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_predicted = model.predict(X_test_norm)\n",
    "mat = confusion_matrix(y_test_encoded.argmax(axis=1), \n",
    "                       y_predicted.argmax(axis=1), \n",
    "                       normalize=\"true\")\n",
    "\n",
    "sns.heatmap(mat, square=True, annot=True, cbar=False, \n",
    "            cmap='Blues', xticklabels=categories, yticklabels=categories)\n",
    "\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('Actual label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test with unrelated WAV files\n",
    "\n",
    "The \"Sounds\" directory has a subdirectory named \"samples\" containing WAV files that the CNN was neither trained nor tested with. The WAV files bear no relation to the samples used for training and testing; they were extracted from a YouTube video documenting Brazil's efforts to curb illegal logging. Let's use the model trained in the previous exercise to analyze these files for sounds of logging activity. Start by creating a spectrogram from the first sample WAV file, which contains audio of loggers cutting down trees in the Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from src.utils import create_mfcc\n",
    "wav_samples = [filename for filename in os.listdir(\"../samples/\") if \"wav\" in filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file = wav_samples[1]\n",
    "print(audio_file)\n",
    "y, sr = librosa.load(f\"../samples/{audio_file}\", sr=16000)\n",
    "placeholders = np.arange(0, len(y)- chunk_len*sr, 0.5*sr, dtype=int)\n",
    "for x1 in placeholders:\n",
    "    x2 = int(x1+chunk_len*sr)\n",
    "    audio_signal = y[x1:x2]\n",
    "    x = create_mfcc(audio_signal, sr, **params)\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = (x-X_train.min()) / (X_train.max() - X_train.min())\n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    for i, label in enumerate(categories):\n",
    "        print(f'Seconds {x1/sr:0.2f}:{x2/sr:.2f} => {label}: {predictions[0][i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
